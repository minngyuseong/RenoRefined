#!/usr/bin/env python3
"""
ëª¨ë“  í…ŒìŠ¤íŠ¸ ê²°ê³¼ë¥¼ ë¶„ì„í•˜ê³  ìš”ì•½í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸
Link Utilization, Latency, Fairnessë¥¼ ê³„ì‚°
"""

import json
import glob
import os
import statistics

# í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ë³„ ë§í¬ ìš©ëŸ‰ ì •ì˜
SCENARIO_CONFIGS = {
    '20_flows': {
        'description': '20ê°œ TCP ì—°ê²°',
        'link_capacity_gbps': 1.0,
        'num_flows': 20
    },
    'high_bw_latency': {
        'description': 'ë†’ì€ ëŒ€ì—­í­ + ë†’ì€ ì§€ì—°',
        'link_capacity_gbps': 10.0,
        'num_flows': 5
    },
    'high_loss': {
        'description': 'ë†’ì€ íŒ¨í‚· ì†ì‹¤',
        'link_capacity_gbps': 1.0,
        'num_flows': 5
    },
    'jitter': {
        'description': 'ì§€ì—° ë³€ë™ (jitter)',
        'link_capacity_gbps': 1.0,
        'num_flows': 5
    }
}

CC_ALGOS = ['reno', 'reno_custom']

def extract_metrics_from_json(json_data):
    """
    iperf3 JSONì—ì„œ throughput, latency ë“± ë©”íŠ¸ë¦­ ì¶”ì¶œ
    """
    metrics = {
        'throughput_bps': 0,
        'mean_rtt_ms': 0,
        'retransmits': 0
    }
    
    # ì—ëŸ¬ ì²´í¬
    if "error" in json_data:
        return metrics
    
    # Throughput ì¶”ì¶œ
    try:
        metrics['throughput_bps'] = json_data["end"]["sum_sent"]["bits_per_second"]
    except:
        try:
            metrics['throughput_bps'] = json_data["end"]["sum"]["bits_per_second"]
        except:
            pass
    
    # Mean RTT ì¶”ì¶œ
    try:
        metrics['mean_rtt_ms'] = json_data["end"]["streams"][0]["sender"]["mean_rtt"] / 1000.0
    except:
        pass
    
    # Retransmits ì¶”ì¶œ
    try:
        metrics['retransmits'] = json_data["end"]["streams"][0]["sender"]["retransmits"]
    except:
        pass
    
    return metrics

def jain_fairness(values):
    """Jain's Fairness Index ê³„ì‚°"""
    if not values or len(values) == 0:
        return 0.0
    s = sum(values)
    s2 = sum(v * v for v in values)
    n = len(values)
    return (s * s) / (n * s2) if s2 > 0 else 0.0

def analyze_scenario(scenario_name, cc_algo):
    """íŠ¹ì • ì‹œë‚˜ë¦¬ì˜¤ì˜ ê²°ê³¼ ë¶„ì„"""
    result_dir = f"/tmp/results_{scenario_name}_{cc_algo}"
    
    if not os.path.exists(result_dir):
        return None
    
    config = SCENARIO_CONFIGS[scenario_name]
    json_files = glob.glob(f"{result_dir}/iperf3_h*_{cc_algo}.json")
    
    if len(json_files) == 0:
        return None
    
    throughputs = []
    latencies = []
    retransmits_total = 0
    
    for json_file in json_files:
        try:
            with open(json_file, 'r') as f:
                data = json.load(f)
            
            metrics = extract_metrics_from_json(data)
            
            if metrics['throughput_bps'] > 0:
                throughputs.append(metrics['throughput_bps'] / 1e9)  # Gbpsë¡œ ë³€í™˜
            
            if metrics['mean_rtt_ms'] > 0:
                latencies.append(metrics['mean_rtt_ms'])
            
            retransmits_total += metrics['retransmits']
            
        except Exception as e:
            continue
    
    if len(throughputs) == 0:
        return None
    
    # ë©”íŠ¸ë¦­ ê³„ì‚°
    total_throughput = sum(throughputs)
    link_utilization = (total_throughput / config['link_capacity_gbps']) * 100.0
    fairness = jain_fairness(throughputs)
    avg_latency = statistics.mean(latencies) if latencies else 0
    
    return {
        'total_throughput_gbps': total_throughput,
        'link_utilization_percent': link_utilization,
        'fairness_index': fairness,
        'avg_latency_ms': avg_latency,
        'retransmits': retransmits_total,
        'num_flows': len(throughputs)
    }

def print_comparison_table():
    """ëª¨ë“  ê²°ê³¼ë¥¼ ë¹„êµ í…Œì´ë¸”ë¡œ ì¶œë ¥"""
    
    print("\n" + "="*100)
    print("ğŸ“Š TCP Congestion Control Performance Comparison")
    print("="*100)
    
    for scenario_name, config in SCENARIO_CONFIGS.items():
        print(f"\n{'='*100}")
        print(f"ğŸ”¬ Scenario: {config['description']}")
        print(f"{'='*100}")
        
        results = {}
        for cc_algo in CC_ALGOS:
            results[cc_algo] = analyze_scenario(scenario_name, cc_algo)
        
        # í—¤ë” ì¶œë ¥
        print(f"\n{'Metric':<30} {'Reno':<25} {'Reno Custom':<25} {'Winner':<15}")
        print("-" * 100)
        
        # Link Utilization
        if results['reno'] and results['reno_custom']:
            reno_util = results['reno']['link_utilization_percent']
            custom_util = results['reno_custom']['link_utilization_percent']
            winner = 'ğŸ† Reno' if reno_util > custom_util else 'ğŸ† Reno Custom' if custom_util > reno_util else 'ğŸ¤ Tie'
            print(f"{'Link Utilization (%)':<30} {reno_util:<24.2f} {custom_util:<24.2f} {winner:<15}")
            
            # Throughput
            reno_tput = results['reno']['total_throughput_gbps']
            custom_tput = results['reno_custom']['total_throughput_gbps']
            winner = 'ğŸ† Reno' if reno_tput > custom_tput else 'ğŸ† Reno Custom' if custom_tput > reno_tput else 'ğŸ¤ Tie'
            print(f"{'Total Throughput (Gbps)':<30} {reno_tput:<24.3f} {custom_tput:<24.3f} {winner:<15}")
            
            # Latency (lower is better)
            reno_lat = results['reno']['avg_latency_ms']
            custom_lat = results['reno_custom']['avg_latency_ms']
            if reno_lat > 0 and custom_lat > 0:
                winner = 'ğŸ† Reno' if reno_lat < custom_lat else 'ğŸ† Reno Custom' if custom_lat < reno_lat else 'ğŸ¤ Tie'
                print(f"{'Average Latency (ms)':<30} {reno_lat:<24.2f} {custom_lat:<24.2f} {winner:<15}")
            
            # Fairness
            reno_fair = results['reno']['fairness_index']
            custom_fair = results['reno_custom']['fairness_index']
            winner = 'ğŸ† Reno' if reno_fair > custom_fair else 'ğŸ† Reno Custom' if custom_fair > reno_fair else 'ğŸ¤ Tie'
            print(f"{'Fairness Index':<30} {reno_fair:<24.3f} {custom_fair:<24.3f} {winner:<15}")
            
            # Retransmits (lower is better)
            reno_retx = results['reno']['retransmits']
            custom_retx = results['reno_custom']['retransmits']
            winner = 'ğŸ† Reno' if reno_retx < custom_retx else 'ğŸ† Reno Custom' if custom_retx < reno_retx else 'ğŸ¤ Tie'
            print(f"{'Total Retransmits':<30} {reno_retx:<24} {custom_retx:<24} {winner:<15}")
        else:
            print("âš ï¸  No valid results found for this scenario")
    
    print("\n" + "="*100)
    print("âœ… Analysis Complete!")
    print("="*100)

def main():
    print_comparison_table()

if __name__ == "__main__":
    main()
